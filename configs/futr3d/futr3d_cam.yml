batch_size: 1
epochs: 24

train_dataset:
  type: NuscenesMVDataset
  dataset_root: data/nuscenes/
  ann_file: data/nuscenes/petr_nuscenes_annotation_train.pkl
  mode: train
  class_names: [
      'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
      'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
  ]
  transforms:
    - type: LoadMultiViewImageFromFiles
      to_float32: True
    - type: LoadAnnotations3D
      with_bbox_3d: True
      with_label_3d: True
    - type: SampleRangeFilter
      point_cloud_range: [ -51.2, -51.2, -5.0, 51.2, 51.2, 3.0 ]
    - type: SampleNameFilter
      classes: [
          'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
          'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
      ]
    - type: NormalizeMultiviewImage
      mean: [ 103.530, 116.280, 123.675 ]
      std: [1.0, 1.0, 1.0]
    - type: PadMultiViewImage
      size_divisor: 32
    - type: SampleFilerByKey
      keys: [ 'gt_bboxes_3d', 'gt_labels_3d','img']


val_dataset:
  type: NuscenesMVDataset
  dataset_root: data/nuscenes/
  ann_file: data/nuscenes/petr_nuscenes_annotation_val.pkl
  mode: val
  class_names: ['car', 'truck', 'construction_vehicle', 'bus', 'trailer',
                    'barrier', 'motorcycle', 'bicycle', 'pedestrian',
                    'traffic_cone']
  transforms:
    - type: LoadMultiViewImageFromFiles
      to_float32: True
    - type: NormalizeMultiviewImage
      mean: [103.530, 116.280, 123.675]
      std: [1.0, 1.0, 1.0]
    - type: PadMultiViewImage
      size_divisor: 32
    - type: SampleFilerByKey
      keys: ['img']

model:
  type: FUTR3D
  use_LiDAR: False
  use_Radar: False
  use_Cam: True
  backbone:
    type: ResNet
    style: 'caffe'
    layers: 101
    return_idx: [0, 1, 2, 3]
    dcn_v2: True
    stage_with_dcn: [False, False, True, True]
    output_stride: None
    frozen_stages: 1
    frozen_norm: True
    preprocess: False
  neck:
    type: FUTR3D_FPN
    in_channels: [256, 512, 1024, 2048]
    out_channels: 256
    start_level: 1
    add_extra_convs: 'on_output'
    num_outs: 4
    relu_before_extra_convs: True
  head:
    type: DeformableFUTR3DHead
    num_query: 600
    num_classes: 10
    in_channels: 256
    embed_dims: 256
    sync_cls_avg_factor: False
    with_box_refine: True
    as_two_stage: False
    code_size: 10
    code_weights: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 0.2]
    num_cls_fcs: 2
    num_reg_fcs: 2
    pc_range: [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]
    transformer:
      type: FUTR3DTransformer
      num_layers: 6
      return_intermediate: True
      embed_dims: 256
      num_heads: 8
      dropout: 0.1
      attn_dropout: 0.1
      use_LiDAR: False
      use_Cam: True
      use_Radar: False
      num_levels: 4
      num_cams: 6
      radar_dims: 64
      radar_topk: 30
      im2col_step: 64
      use_dconv: True
      feedforward_channels: 512
      feedforward_dropout: 0.1
      normalize_before: False
      pc_range: [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]
    bbox_coder:
      type: NMSFreeCoder
      post_center_range: [-61.2, -61.2, -10.0, 61.2, 61.2, 10.0]
      pc_range: [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]
      max_num: 300
      voxel_size: [0.2, 0.2, 8]
      num_classes: 10
    loss_cls:
      type: WeightedFocalLoss
      gamma: 2.0
      alpha: 0.25
      loss_weight: 2.0
    loss_bbox:
      type: WeightavgL1Loss
      loss_weight: 0.25


optimizer:
  type: AdamW
  weight_decay: 0.01
  grad_clip:
    type: ClipGradByGlobalNorm
    clip_norm: 35

lr_scheduler:
  type: LinearWarmup
  learning_rate:
    type: MultiStepDecayByEpoch
    learning_rate: 0.0001
    milestones: [21, 23]
    gamma: 0.1
  warmup_steps: 500
  start_lr: 0.0
  end_lr: 0.0001
